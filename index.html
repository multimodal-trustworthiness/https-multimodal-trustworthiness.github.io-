<!DOCTYPE html>
<html lang="zh-CN">
	<head>
		<title>The Blind Men and the Elephant: Introducing Machine-Learning-Based Data Fusion Methods for Multimodal Data and an Application of Measuring Trustworthiness</title>
		<meta name="description" content="">
		<meta name="author" content="">
		<meta name="keywords" content="">
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" href="css/uikit.min.css" />
		<link rel="stylesheet" href="css/main.css" />
		<script src="js/uikit.min.js"></script>
		<script src="js/jquery.min.js"></script>
		<script src="js/uikit-icons.min.js"></script>
        <script src="js/script.js"></script>
		</head>

	<body oncontextmenu=self.event.returnValue=false>

		<nav class="uk-navbar-container uk-margin" uk-navbar uk-sticky>
		    <div class="uk-navbar-left">
			        <a href="#offcanvas-slide" uk-icon="icon: menu" uk-toggle></a>

						<div id="offcanvas-slide" uk-offcanvas="mode: push">
						    <div class="uk-offcanvas-bar">

						        <ul class="uk-nav uk-nav-default">
						            <li class="uk-nav-header"><a href="#1" uk-scroll><b>1. Distribution of videos across product categories</b></a></li>
						            <li class="uk-nav-header"><a href="#2" uk-scroll><b>2. Live streaming commerce video sample</b></a></li>
						            <li class="uk-nav-header"><a href="#3" uk-scroll><b>3. Feature extraction summary</b></a></li>
						            <li><a href="#3.1" uk-scroll>3.1 OpenFace</a></li>
						            <li><a href="#3.2" uk-scroll>3.2 Covarep</a></li>
						            <li><a href="#3.3" uk-scroll>3.3 AliNLP</a></li>
						            <li class="uk-nav-header"><a href="#4" uk-scroll><b>4. Model Architecture</b></a></li>
						            <li><a href="#4.1" uk-scroll>4.1 Architecture of LSTM model with late fusion (LF-LSTM model)</a></li>
						            <li><a href="#4.2" uk-scroll>4.2 Architecture of LSTM model with early fusion (EF-LSTM model)</a></li>
						            <li class="uk-nav-header"><a href="#5" uk-scroll><b>5. Validation performance</b></a></li>
						            <li class="uk-nav-header"><a href="#6" uk-scroll><b>6. Results for multimodal trustworthiness analysis</b></a></li>
						        </ul>

						    </div>
						</div>
		    </div>

		        <!--div class="uk-navbar-right">
		        		<div class="uk-inline">
						    <a type="button" uk-icon="icon: world"></a>
						    <div uk-drop="mode: click">
						        <div class="uk-card uk-card-body uk-card-default" style="text-align: center;padding: 10px;width: auto;">
						        	<a href="https://zhengfang-research.github.io/multimodal_trustworthiness/" target="_blank" style="margin-right: 10px;">Gitub</a>
						        	<a href="https://zhengfang-research.gitee.io/multimodal_trustworthiness/" target="_blank">Gitee</a>
						        </div>
						    </div>
						</div>
			    </div-->

		    
		</nav>


<div class="banner">
	<div class="uk-container uk-container-center container">
		<div class="large-title">
				The Blind Men and the Elephant: <br>Introducing Machine-Learning-Based Data Fusion Methods for Multimodal Data and an Application of Measuring Trustworthiness
			</div>

			<div class="content" style="margin-top:100px">
						<h1>Abstract</h1>
						<p>Multimodal data—unstructured text, image, and/or audio data that interdependently characterize the same source—offer a wealth of information for strategy researchers. We discuss the tradeoffs of using text versus non-text data and the conditions that call for incorporating non-text data to increase predictive accuracy. We then introduce cutting-edge machine deep learning and data fusion methods that holistically account for both intra- and inter-modality interactions, to automate the analyses of video data, the most prevalent form of multimodal data. We provide empirical demonstration by measuring the trustworthiness of sellers in live streaming commerce on TikTok and showing its importance to making sales. This paper expands the empirical toolbox for unstructured multimodal data analysis and advocates for data fusion in multiple areas of strategy research.</p>
						<div class="content" style="margin-top:10px">
							<h1>The data and codes can be found in：  <a href="https://drive.google.com/drive/folders/16swSGwI6aAU_sdpDljztrO8O8PHYa3JL?usp=sharing" class="uk-icon-button" uk-icon="github" target="_blank" style="background: #d9d9d9;"></a></h1>
					
		</div>
	</div>
</div>

		<div class="uk-container uk-container-center container" id="content">
			<div class="catalog">
				<h1>Data, Models and Results of Machine Learning</h1>
				<h3>CONTENT</h3>
				<ul class="uk-nav uk-nav-default">
						            <li class="uk-nav-header"><a href="#1" uk-scroll><b>1. Distribution of videos across product categories</b></a></li>
						            <li class="uk-nav-header"><a href="#2" uk-scroll><b>2. Live streaming commerce video sample</b></a></li>
						            <li class="uk-nav-header"><a href="#3" uk-scroll><b>3. Feature extraction summary</b></a></li>
						            <li><a href="#3.1" uk-scroll>3.1 OpenFace</a></li>
						            <li><a href="#3.2" uk-scroll>3.2 Covarep</a></li>
						            <li><a href="#3.3" uk-scroll>3.3 AliNLP</a></li>
						            <li class="uk-nav-header"><a href="#4" uk-scroll><b>4. Model Architecture</b></a></li>
						            <li><a href="#4.1" uk-scroll>4.1 Architecture of LSTM model with late fusion (LF-LSTM model)</a></li>
						            <li><a href="#4.2" uk-scroll>4.2 Architecture of LSTM model with early fusion (EF-LSTM model)</a></li>
						            <li class="uk-nav-header"><a href="#5" uk-scroll><b>5. Validation performance</b></a></li>
						            <li class="uk-nav-header"><a href="#6" uk-scroll><b>6. Results for multimodal trustworthiness analysis</b></a></li>
						        </ul>			
			</div>

			<div class="uk-grid-small" uk-grid>
				<div class="uk-width-1-1">
				<div class="content">
						<h1 id="1">1. Distribution of observations across product categories</h1>
						
						<div class="uk-width-1-1" uk-lightbox="animation: slide" style="text-align: center;">
							<a href="media/1-1.webp" data-caption="" class="apic-pc"><img src="media/1-1.webp" alt="" style="width: 100%;"></a>
							<a href="media/1-2.webp" data-caption="" class="apic-h5"><img src="media/1-2.webp" alt="" style="width: 100%;"></a>
						</div>

				<h1 id="2">2. Live streaming commerce video sample</h1>
				<div class="video">
					<iframe height="" width="100%" src="https://player.bilibili.com/player.html?bvid=BV1vd4y1B74h&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
		        </div>
				</div>

				<h1 id="3">3. Feature extraction summary</h1>
					<div class="img-list" uk-lightbox="animation: slide">
						<div class="img-list-pic">
							<a href="media/1.webp" data-caption="Table 1. Summary of Multimodal Feature Extraction"><img src="media/1.webp" alt=""></a>
						</div>
					</div>

				<h2 id="3.1">3.1 OpenFace</h2>

				<div class="uk-grid-small" uk-grid uk-height-match>
				<div class="uk-width-1-1 uk-width-1-3@m">
					<div class="video2">
						<iframe height="" width="100%" src="https://player.bilibili.com/player.html?bvid=BV1pT411u7bq&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
					</div>
				</div>
				<div class="uk-width-1-1 uk-width-2-3@m" uk-lightbox="animation: slide">
					<a href="media/2.webp" data-caption=""><img src="media/2.webp" alt=""></a>
				</div>
				</div>

				<h2 id="3.2">3.2 Covarep</h2>
				<div class="uk-grid-small" uk-grid>
					<div class="uk-width-1-1" uk-lightbox="animation: slide">
					<div style="max-width: 800px;margin:auto">
						<a href="media/3.webp" data-caption=""><img src="media/3.webp" alt=""></a>
					</div>
					<p>
						<div class="audio">
							<audio controls><source src="media/media.mp3" type="audio/mpeg" controlsList="nodownload">您的浏览器不支持 audio 元素。</audio>
						</div>
					</p>
				</div>
				</div>			

				<h2 id="3.3">3.3 AliNLP</h2>
				<div class="uk-grid-medium" uk-grid>
				<div class="uk-width-1-1" uk-lightbox="animation: slide">
					<div style="max-width: 650px;margin:auto">
						<a href="media/9.webp" data-caption=""><img src="media/9.webp" alt=""></a>
					</div>
					<p style="text-align:center;">Synonyms(left) and antonyms(right) of trustworthiness with word embedding of AliNLP</p>
				</div>
				</div>

				
				<h1 id="4">4. Model Architecture</h1>
				<h3 id="4.1">4.1 Architecture of LSTM model with late fusion (LF-LSTM model)</h3>
				<div class="img-list" uk-lightbox="animation: slide">
						<div class="img-list-pic">
							<a href="media/4.webp" data-caption="TFigure 4.1 Architecture of LSTM model with late fusion (LF-LSTM model)"><img src="media/4.webp" alt=""></a>
						</div>
					</div>
				<h3 style="margin-top: 80px;" id="4.2">4.2 Architecture of LSTM model with early fusion (EF-LSTM model)</h3>
				<div class="img-list" uk-lightbox="animation: slide">
						<div class="img-list-pic">
							<a href="media/5.webp" data-caption="Figure 4.2 Architecture of LSTM model with early fusion (EF-LSTM model)"><img src="media/5.webp" alt=""></a>
						</div>
					</div>

				<h1 id="5">5. Validation performance</h1>
				<div>
					<ul class="uk-subnav uk-subnav-pill" uk-switcher>
					    <li><a href="#">Figure 5.1 Acc2</a></li>
					    <li><a href="#">Figure 5.2 F1-Sccore</a></li>
					    <li><a href="#">Figure 5.3 MAE</a></li>
					    <li><a href="#">Figure 5.4 MSE</a></li>
					    <li><a href="#">Figure 5.5 Corr</a></li>
					</ul>
				

				<ul class="uk-switcher">
				    <li>
				    	<div><img src="media/acc12.webp" width="100%"></div>
				    </li>
				    <li>
				    	<div><img src="media/f1score12.webp" width="100%"></div>
				    </li>
				    <li>
				    	<div><img src="media/mae12.webp" width="100%"></div>
				    </li>
				    <li>
				    	<div><img src="media/mse12.webp" width="100%"></div>
				    </li>
				    <li>
				    	<div><img src="media/corr12-1.webp" width="100%"></div>
				    </li>
				</ul>
				<p style="text-align:center;font-size: 0.83em;margin:-5px 0 0 0">Epoch</p>

				</div>



				<div class="color">
					<ul>
						<li><div style="background: #c00000" class="color-model"></div>CTC+EF-LSTM (verbal+vocal+visual) </li>
						<li><div style="background: #c5e0b4" class="color-model"></div>LF-LSTM (verbal+vocal+visual) </li>
						<li><div style="background: #c55a11" class="color-model"></div>CTC+EF-LSTM (verbal+vocal) </li>
						<li><div style="background: #f4b183" class="color-model"></div>CTC+EF-LSTM (verbal+visual) </li>
						<li><div style="background: #ffc000" class="color-model"></div>CTC+EF-LSTM (vocal+visual) </li>
						<li><div style="background: #0d0d0d" class="color-model"></div>LF-LSTM (verbal+vocal) </li>						
						<li><div style="background: #ffe699" class="color-model"></div>LF-LSTM (verbal+visual)</li>
						<li><div style="background: #548235" class="color-model"></div>LF-LSTM (vocal+visual) </li>
						<li><div style="background: #bdd7ee" class="color-model"></div>LSTM (verbal) </li>
						<li><div style="background: #bfbfbf" class="color-model"></div>LSTM (vocal) </li>					
						<li><div style="background: #2e75b6" class="color-model"></div>LSTM (visual)</li>				
					</ul>
				</div>

				</div>

			<h1 id="6">6. Results for multimodal trustworthiness analysis</h1>
			<div class="img-list" uk-lightbox="animation: slide">
						<div class="img-list-pic">
							<a href="media/6.png" data-caption="Table *. Performance of Binary-Class and Multi-Class Classifications by Different Deep Learning Models"><img src="media/6.png" alt=""></a>
						</div>
					</div>
		
			   <div class="img-model6">
			                <img src="media/note.webp" alt="">
			   </div>
			<div class="img-model7" style="padding-bottom: 60px;">
					<img src="media/note.png" alt="">
			</div>

				</div>
			</div>
		</div>


<a href="" uk-totop class="totop" uk-scroll><span uk-icon="top"></span></a>
	</body>
</html>
